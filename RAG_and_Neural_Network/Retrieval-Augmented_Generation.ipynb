{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation (RAG):\n",
    "\n",
    "It is a powerful approach for improving the accuracy and credibility of natural language generation models by integrating external knowledge retrieval into the generation process. This method mitigates one of the key limitations of traditional models, namely hallucination (producing information that is factually incorrect or unverifiable). Here's a breakdown of how RAG works and its effectiveness in citing sources and preventing hallucinations:\n",
    "\n",
    "## How RAG Works:\n",
    "\n",
    "### Query Encoding: \n",
    "The input query or prompt is encoded into a representation.\n",
    "\n",
    "### Document Retrieval: \n",
    "The query representation is used to retrieve relevant documents from an external corpus (often a knowledge base or database). This can be done using similarity search techniques.\n",
    "\n",
    "### Response Generation: \n",
    "Instead of relying solely on the model's pre-trained knowledge, the retrieved documents are fed into the model alongside the query. The model uses these documents to generate a response that is grounded in the retrieved information.\n",
    "\n",
    "### Citing Sources: \n",
    "As the retrieved documents are used to generate responses, RAG provides an inherent ability to cite the sources by linking the generated content to the documents that informed it.\n",
    "\n",
    "## Effectiveness in Preventing Hallucinations:\n",
    "\n",
    "### Grounding in Factual Data: \n",
    "By retrieving and incorporating factual information from an external corpus, RAG ensures that the generated content is rooted in verifiable data, drastically reducing the chance of hallucination.\n",
    "\n",
    "### Transparency: \n",
    "Since the retrieval process identifies specific documents or data that informed the response, RAG provides transparency, making it clear where the information comes from. This allows users to trace the information back to the original source, which is critical for verification.\n",
    "\n",
    "### Accuracy and Relevance: \n",
    "RAG not only reduces hallucinations but also improves the relevance of the generated responses. By pulling in data from a focused corpus (e.g., academic articles, product documentation), the model generates content that is both more accurate and tailored to the specific query.\n",
    "\n",
    "## Example Demonstrating RAG's Effectiveness:\n",
    "\n",
    "### Imagine a user asks a RAG model: \n",
    "\"What are the benefits of using GPT-4 for educational purposes?\" The model retrieves external documents related to GPT-4, such as research papers or educational articles. Based on the retrieved content, it might generate a response like this:\n",
    " \n",
    "GPT-4 offers several educational benefits, including personalized tutoring through conversational interfaces, scalable content creation for curriculum design, and enhanced engagement in learning environments. A recent study by [Smith et al., 2023] highlights how GPT-4 significantly improved learning outcomes in a trial involving middle school students. Additionally, the AI's ability to provide instant feedback on student work fosters a more interactive learning experience (Jones et al., 2022).\n",
    "\n",
    "In this case, the RAG system has not only provided an accurate and detailed response but also cited the relevant studies that informed the generated content, thus preventing hallucinations and ensuring traceability of the information.\n",
    "\n",
    "## Conclusion:\n",
    "RAG effectively reduces hallucination by grounding the model's responses in factual data retrieved from external sources. It enhances transparency by enabling the model to cite sources and offers a higher degree of reliability compared to standard generation models that rely solely on pre-trained knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvCIoDA5Z8Yd",
    "outputId": "aa52e500-51c5-4e10-f126-ee6356896c13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== NON-RAG RESPONSE ====\n",
      "There is no specific US Department of Government Efficiency. However, there are various government agencies and offices dedicated to improving government efficiency and effectiveness, such as the Office of Management and Budget (OMB) and the Government Accountability Office (GAO).\n",
      "\n",
      "The head of the OMB is the Director, who is appointed by the President and confirmed by the Senate. As of October 2021, the Director of the OMB is Shalanda Young. The head of the GAO is the Comptroller General, who is appointed by the President and confirmed by the Senate. As of October 2021, the Comptroller General of the GAO is Gene L. Dodaro.\n",
      "\n",
      "==== RAG RESPONSE ====\n",
      "=== INPUT PARSING ===\n",
      "Original user query: What is the US Department of Government Efficiency who heads it?\n",
      "Augmented user query: What is the US Department of Government Efficiency who heads it?Be specefic with your answer\n",
      "\n",
      "=== OUTPUT PARSING ===\n",
      "Raw RAG answer: The U.S. Department of Government Efficiency (DOGE) is a temporary organization within the U.S. federal government aimed at modernizing federal technology and software to enhance governmental efficiency and productivity. It was established by President Donald Trump on January 20, 2025. Elon Musk leads the DOGE organization.\n",
      "Augmented RAG answer: The answer to your question is: The U.S. Department of Government Efficiency (DOGE) is a temporary organization within the U.S. federal government aimed at modernizing federal technology and software to enhance governmental efficiency and productivity. It was established by President Donald Trump on January 20, 2025. Elon Musk leads the DOGE organization.\n",
      "\n",
      "=== OUTPUT FORMATTING ===\n",
      "Answer: The answer to your question is: The U.S. Department of Government Efficiency (DOGE) is a temporary organization within the U.S. federal government aimed at modernizing federal technology and software to enhance governmental efficiency and productivity. It was established by President Donald Trump on January 20, 2025. Elon Musk leads the DOGE organization.\n",
      "Source: DOGE_Government_Announcement.docx\n",
      "\n",
      "=== FINAL RAG OUTPUT ===\n",
      "Answer: The answer to your question is: The U.S. Department of Government Efficiency (DOGE) is a temporary organization within the U.S. federal government aimed at modernizing federal technology and software to enhance governmental efficiency and productivity. It was established by President Donald Trump on January 20, 2025. Elon Musk leads the DOGE organization.\n",
      "Source: DOGE_Government_Announcement.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not set in .env\")\n",
    "\n",
    "# SAMPLE DOCUMENTS FOR RAG\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        The Department of Government Efficiency (DOGE) is a temporary organization within the U.S. federal government, established by President Donald Trump on January 20, 2025, through an executive order. Officially named the U.S. DOGE Service Temporary Organization, it operates under the United States DOGE Service, formerly known as the United States Digital Service. Despite its name, DOGE is not a federal executive department, as such a designation would require congressional approval.\n",
    "WHITEHOUSE.GOV\n",
    "\n",
    "Purpose and Objectives\n",
    "\n",
    "DOGE's primary mission is to modernize federal technology and software to enhance governmental efficiency and productivity. The executive order outlines its role in implementing the President's DOGE Agenda, focusing on:\n",
    "\n",
    "Modernizing federal technology and software.\n",
    "Maximizing governmental efficiency and productivity.\n",
    "Initially, DOGE aimed to reduce wasteful spending and eliminate unnecessary regulations. However, its formal mandate emphasizes technological modernization as the pathway to increased efficiency.\n",
    "WHITEHOUSE.GOV\n",
    "\n",
    "Leadership and Structure\n",
    "\n",
    "Elon Musk leads DOGE, following the departure of initial co-leader Vivek Ramaswamy before the organization's official launch. DOGE is headquartered in the Eisenhower Executive Office Building in Washington, D.C., with approximately 20 employees and teams embedded within various federal agencies.\n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "Key Initiatives and Proposals\n",
    "\n",
    "DOGE has proposed several measures to achieve its objectives:\n",
    "\n",
    "Elimination of Agencies: Proposals include abolishing entities such as the Consumer Financial Protection Bureau and restructuring financial regulatory bodies like the Federal Deposit Insurance Corporation (FDIC), Office of the Comptroller of the Currency (OCC), and the Federal Reserve.\n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "Workforce Reduction: Plans to reduce the federal workforce by up to 75% through measures like re-enacting Schedule F, which would reclassify certain federal employees to facilitate easier dismissal.\n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "Budget Cuts: Aiming to cut up to $2 trillion from the federal budget by reducing waste, eliminating redundant agencies, and downsizing the federal workforce.\n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "Lifespan and Future Outlook\n",
    "\n",
    "DOGE is designed as a temporary organization, with its operations set to conclude by July 4, 2026, coinciding with the United States Semiquincentennial. This timeline aligns with the goal of implementing efficient government reforms within a defined period.\n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "Reception and Legal Considerations\n",
    "\n",
    "The establishment and operations of DOGE have sparked discussions regarding potential conflicts of interest, given Elon Musk's leadership and his companies' involvement in government contracts. Legal challenges have been raised concerning the organization's adherence to federal transparency and advisory committee regulations.\n",
    "EN.WIKIPEDIA.ORG\n",
    "\n",
    "In summary, the Department of Government Efficiency represents a significant initiative aimed at overhauling federal operations through technological modernization and structural reforms. Its progress and impact will be closely monitored as it pursues its ambitious objectives within the established timeframe.\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"DOGE_Government_Announcement.docx\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# CREATE A VECTOR STORE (FAISS) AND RETRIEVER\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embedding)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "# CREATE A CHAT LLM\n",
    "chat_llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# CREATE THE RETRIEVAL QA CHAIN\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "############################################\n",
    "# 1) NON-RAG RESPONSE\n",
    "############################################\n",
    "def non_rag_response(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a direct, raw response from the LLM without any retrieval augmentation.\n",
    "    \"\"\"\n",
    "    return chat_llm.predict(user_query)\n",
    "\n",
    "############################################\n",
    "# 2) RAG RESPONSE\n",
    "############################################\n",
    "def rag_response(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a user query, processes it through the RAG pipeline,\n",
    "    and returns a formatted answer along with the source.\n",
    "    \"\"\"\n",
    "\n",
    "    # INPUT PARSING\n",
    "    print(\"=== INPUT PARSING ===\")\n",
    "    print(\"Original user query:\", user_query)\n",
    "    # Augment the query\n",
    "    parsed_query = user_query + \"Be specefic with your answer\"\n",
    "    print(\"Augmented user query:\", parsed_query)\n",
    "\n",
    "    # Use the augmented query for retrieval + generation\n",
    "    result = qa_chain({\"query\": parsed_query})\n",
    "\n",
    "    # OUTPUT PARSING\n",
    "    print(\"\\n=== OUTPUT PARSING ===\")\n",
    "    raw_answer = result[\"result\"]\n",
    "    retrieved_docs = result[\"source_documents\"]\n",
    "\n",
    "    print(\"Raw RAG answer:\", raw_answer)\n",
    "    parsed_answer = \"The answer to your question is: \" + raw_answer\n",
    "    print(\"Augmented RAG answer:\", parsed_answer)\n",
    "\n",
    "    # OUTPUT FORMATTING\n",
    "    print(\"\\n=== OUTPUT FORMATTING ===\")\n",
    "    if retrieved_docs and len(retrieved_docs) > 0:\n",
    "        source_info = retrieved_docs[0].metadata[\"source\"]\n",
    "    else:\n",
    "        source_info = \"No Source Found\"\n",
    "\n",
    "    final_output = f\"Answer: {parsed_answer}\\nSource: {source_info}\"\n",
    "    print(final_output)\n",
    "\n",
    "    return final_output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"What is the US Department of Government Efficiency who heads it?\"\n",
    "\n",
    "    # 1) Non-RAG Direct Response\n",
    "    print(\"\\n==== NON-RAG RESPONSE ====\")\n",
    "    direct_answer = non_rag_response(user_query)\n",
    "    print(direct_answer)\n",
    "\n",
    "    # 2) RAG Response\n",
    "    print(\"\\n==== RAG RESPONSE ====\")\n",
    "    rag_answer = rag_response(user_query)\n",
    "    print(\"\\n=== FINAL RAG OUTPUT ===\")\n",
    "    print(rag_answer)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
